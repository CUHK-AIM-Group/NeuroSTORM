<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <style>
    .content a {
      color: #1e90ff;   /* 你可以换成你喜欢的颜色，如 #e67e22, #007bff 等 */
      text-decoration: underline;
      transition: color 0.2s;
    }
    .content a:hover {
      color: #ff6600;   /* 鼠标悬停时的颜色 */
    }
    .carousel.results-carousel img {
      max-width: 800px;
      width: 750%;
      height: auto;
      display: block;
      margin: 0 auto;
    }
  </style>
  
  <title>Academic Project Page</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <link rel="icon" type="image/png" href="static/images/icon.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              <img src="static/images/icon.png" alt="NeuroSTORM Icon" style="height: 2.0em; vertical-align: middle; margin-right: 0.1em;">
              NeuroSTORM: A Deep Learning Platform for fMRI Analysis
            </h1>
            <div class="is-size-5 publication-authors">
                  <!-- Paper authors -->
                  <div class="column has-text-centered">
                  <div class="publication-links">

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/CUHK-AIM-Group/NeuroSTORM" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                <a href="https://huggingface.co/zxcvb20001/NeuroSTORM" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="Hugging Face" style="height:1.2em;vertical-align:middle;">
                  </span>
                  <span>HuggingFace</span>
                </a>
              </span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/stage1.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          NeuroSTORM provides preprocessing tools for both volume-based and ROI-based methods.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/stage2.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          NeuroSTORM enables model training with customizable models and datasets.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/stage3.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Users can add custom downstream tasks to NeuroSTORM.
       </h2>
     </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->


<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">1. Develop Deep-learning Methods with NeuroSTORM</h2>
      <div class="content">

        <ol>
          <li>
            <strong>How to preprocess your own data with NeuroSTORM</strong>
            <ul>
              <li>
                <b>Pre-processing:</b> 
                Please make sure you have completed the primary preprocessing pipeline, such as 
                <a href="https://fsl.fmrib.ox.ac.uk/fsl/docs/#/" target="_blank">FSL</a>,
                <a href="https://fmriprep.org/en/stable/" target="_blank">fMRIPrep</a>,
                or the <a href="https://github.com/Washington-University/HCPpipelines" target="_blank">HCP pipeline</a>, 
                and your data is aligned to MNI152 space.
                You may also use our provided shell script for brain extraction:
                <a href="https://github.com/CUHK-AIM-Group/NeuroSTORM/blob/main/datasets/brain_extraction.sh" target="_blank">brain_extraction.sh</a>
                (based on FSL BET, please install 
                <a href="https://fsl.fmrib.ox.ac.uk/fsl/docs/#/" target="_blank">FSL tool</a> first).
                After running, brain mask files in <code>.nii.gz</code> format will be generated in the output directory.
              </li>
              <li>
                <b>Prepare 4D input:</b> 
                Use <a href="https://github.com/CUHK-AIM-Group/NeuroSTORM/blob/main/datasets/preprocessing_volume.py" target="_blank">preprocessing_volume.py</a> 
                to preprocess your data for model input. This tool supports bulk dataset processing, including background removal, resampling, Z-normalization, and saving frames as <code>.pt</code> files. If CPU is limited, preprocess in advance; if disk speed is the bottleneck, online preprocessing during training is an option.
              </li>
              <li>
                <b>Prepare 2D input:</b> 
                Use <a href="https://github.com/CUHK-AIM-Group/NeuroSTORM/blob/main/datasets/generate_roi_data_from_nii.py" target="_blank">generate_roi_data_from_nii.py</a>
                to convert 3D/4D data to 2D ROI-based data using available brain atlases. Multiple datasets and atlases are supported.
              </li>
            </ul>
          </li>

          <li>
            <strong>How to run existing methods on supported datasets</strong>
            <br>
            You can use our prepared scripts to quickly reproduce the experiments from the paper: 
            <a href="https://github.com/CUHK-AIM-Group/NeuroSTORM/tree/main/scripts" target="_blank">scripts</a>
          </li>

          <li>
            <strong>How to add new methods</strong>
            <ul>
              <li>
                Add your model definition in 
                <a href="https://github.com/CUHK-AIM-Group/NeuroSTORM/tree/main/models" target="_blank">models</a>,
                and add the task head in 
                <a href="https://github.com/CUHK-AIM-Group/NeuroSTORM/tree/main/models/heads" target="_blank">models/heads</a>.
              </li>
              <li>
                If additional inputs or outputs are needed, modify 
                <a href="https://github.com/CUHK-AIM-Group/NeuroSTORM/blob/main/models/lightning_model.py" target="_blank">lightning_model.py</a>.
              </li>
            </ul>
          </li>

          <li>
            <strong>How to adapt NeuroSTORM to new datasets</strong>
            <ul>
              <li>
                Please preprocess fMRI sequences and align to MNI152 space using tools like 
                <a href="https://fmriprep.org/en/stable/" target="_blank">fMRIPrep</a>,
                <a href="https://github.com/Washington-University/HCPpipelines" target="_blank">HCP pipelines</a>,
                or refer to 
                <a href="https://biobank.ctsu.ox.ac.uk/crystal/crystal/docs/brain_mri.pdf" target="_blank">UK Biobank MRI</a>.
              </li>
              <li>
                Add your dataset in 
                <a href="https://github.com/CUHK-AIM-Group/NeuroSTORM/blob/main/datasets/preprocessing_volume.py" target="_blank">preprocessing_volume.py</a>.
                Modify:
                <ul>
                  <li>The naming convention for Volume data, in <code>determine_subject_name</code> function</li>
                  <li>Choose the resize method: if similar to HCP-YA, use <code>select_middle_96</code>, otherwise use <code>resize_to_96</code></li>
                </ul>
              </li>
              <li>
                Initialize your dataset in 
                <a href="https://github.com/CUHK-AIM-Group/NeuroSTORM/blob/main/datasets/fmri_datasets.py" target="_blank">fmri_datasets.py</a>,
                and define loader in 
                <a href="https://github.com/CUHK-AIM-Group/NeuroSTORM/blob/main/utils/data_module.py" target="_blank">data_module.py</a>
              </li>
            </ul>
          </li>

          <li>
            <strong>How to add new tasks</strong>
            <ul>
              <li>
                Define the dataset label format in the <code>make_subject_dict</code> function from 
                <a href="https://github.com/CUHK-AIM-Group/NeuroSTORM/blob/main/utils/data_module.py" target="_blank">data_module.py</a>
              </li>
              <li>
                Set the task type by specifying <code>--downstream_task</code> in the script.
              </li>
              <li>
                Choose a classification or regression head. For custom tasks, add a new head definition in 
                <a href="https://github.com/CUHK-AIM-Group/NeuroSTORM/tree/main/models/heads" target="_blank">models/heads</a>
              </li>
            </ul>
          </li>

          <li>
            <strong>Related Links</strong>
            <ul>
              <li><a href="https://github.com/Transconnectome/SwiFT" target="_blank">SwiFT</a></li>
              <li><a href="https://github.com/LifangHe/BrainGNN_Pytorch" target="_blank">BrainGNN_Pytorch</a></li>
              <li><a href="https://github.com/MedARC-AI/MindEyeV2" target="_blank">MindEyeV2</a></li>
              <li><a href="https://fsl.fmrib.ox.ac.uk/fsl/docs" target="_blank">FSL Docs</a></li>
              <li><a href="https://github.com/Washington-University/HCPpipelines" target="_blank">HCP Pipelines</a></li>
              <li><a href="https://github.com/nipreps/fmriprep" target="_blank">fMRIPrep</a></li>
            </ul>
          </li>
        </ol>

      </div>
    </div>
  </div>
</section>

<!--End paper poster -->


<!-- Supported Dataset -->
<section class="hero is-white">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">2. Supported Datasets</h2>
      <div class="content">

        <p>
          NeuroSTORM supports a wide range of publicly available fMRI datasets for both pre-training and downstream analysis. The table below summarizes key characteristics of each dataset, including the subject number, male/female ratio, spatial resolution, TR, and official homepage.
        </p>

        <table class="table is-striped is-hoverable is-fullwidth" style="font-size:1em;">
          <thead>
            <tr>
              <th>Dataset Name (Abbreviation)</th>
              <th>Subjects<br/>(Male/Female)</th>
              <th>Spatial Resolution</th>
              <th>TR (ms)</th>
              <th>Homepage</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><b>UK Biobank (UKB)</b></td>
              <td>40,842<br>(17,720 / 23,122)</td>
              <td>2.4 × 2.4 × 2.4 mm³</td>
              <td>735</td>
              <td><a href="https://www.ukbiobank.ac.uk/" target="_blank">Link</a></td>
            </tr>
            <tr>
              <td><b>Adolescent Brain Cognitive Development (ABCD)</b></td>
              <td>9,448<br>(4,931 / 4,517)</td>
              <td>2.4 × 2.4 × 2.4 mm³</td>
              <td>800</td>
              <td><a href="https://abcdstudy.org/" target="_blank">Link</a></td>
            </tr>
            <tr>
              <td><b>Human Connectome Project - Young Adult (HCP-YA)</b></td>
              <td>1,206<br>(550 / 656)</td>
              <td>2 × 2 × 2 mm³</td>
              <td>720</td>
              <td><a href="https://www.humanconnectome.org/" target="_blank">Link</a></td>
            </tr>
            <tr>
              <td><b>Human Connectome Project - Aging (HCP-A)</b></td>
              <td>725<br>(319 / 406)</td>
              <td>2 × 2 × 2 mm³</td>
              <td>800</td>
              <td><a href="https://www.humanconnectome.org/study/hcp-lifespan-aging" target="_blank">Link</a></td>
            </tr>
            <tr>
              <td><b>Human Connectome Project - Development (HCP-D)</b></td>
              <td>652<br>(301 / 351)</td>
              <td>2 × 2 × 2 mm³</td>
              <td>800</td>
              <td><a href="https://www.humanconnectome.org/study/hcp-lifespan-development" target="_blank">Link</a></td>
            </tr>
            <tr>
              <td><b>Human Connectome Project - Early Psychosis (HCP-EP)</b></td>
              <td>252<br>(94 / 158)</td>
              <td>2 × 2 × 2 mm³</td>
              <td>800</td>
              <td><a href="https://www.humanconnectome.org/study/hcp-early-psychosis" target="_blank">Link</a></td>
            </tr>
            <tr>
              <td><b>ADHD-200 Sample (ADHD200)</b></td>
              <td>973<br>(600 / 373)</td>
              <td>3 × 3 × 4 mm³</td>
              <td>2000</td>
              <td><a href="http://fcon_1000.projects.nitrc.org/indi/adhd200/" target="_blank">Link</a></td>
            </tr>
            <tr>
              <td><b>Autism Brain Imaging Data Exchange (ABIDE)</b></td>
              <td>1,112<br>(948 / 164)</td>
              <td>3 × 3 × 3 mm³</td>
              <td>2000</td>
              <td><a href="http://fcon_1000.projects.nitrc.org/indi/abide/" target="_blank">Link</a></td>
            </tr>
            <tr>
              <td><b>UCLA Consortium for Neuropsychiatric Phenomics (UCLA)</b></td>
              <td>272<br>(222 / 50)</td>
              <td>3 × 3 × 4 mm³</td>
              <td>2000</td>
              <td><a href="https://openneuro.org/datasets/ds000030" target="_blank">Link</a></td>
            </tr>
            <tr>
              <td><b>Center for Biomedical Research Excellence (COBRE)</b></td>
              <td>173<br>(130 / 43)</td>
              <td>3.75 × 3.75 × 4.55 mm³</td>
              <td>2000</td>
              <td><a href="https://fcon_1000.projects.nitrc.org/indi/retro/cobre.html" target="_blank">Link</a></td>
            </tr>
            <tr>
              <td><b>Motor Neuron Disease fMRI Dataset (MND)</b></td>
              <td>59<br>(44 / 15)</td>
              <td>2.395 × 2.395 × 2.4 mm³</td>
              <td>2000</td>
              <td>--</td>
            </tr>
            <tr>
              <td><b>Transdiagnostic Connectome Project (TCP)</b></td>
              <td>245<br>(143 / 102)</td>
              <td>2 × 2 × 2 mm³</td>
              <td>800</td>
              <td><a href="https://openneuro.org/datasets/ds004215" target="_blank">Link</a></td>
            </tr>
          </tbody>
        </table>

        <h3>Dataset Descriptions</h3>
        <ul>
          <li>
            <b>UK Biobank (UKB):</b>
            A large-scale prospective study from the UK containing health, genetic, and neuroimaging data of over 40,000 middle-aged participants. fMRI is acquired at 2.4mm isotropic resolution (TR=735ms).
          </li>
          <li>
            <b>Adolescent Brain Cognitive Development (ABCD):</b>
            Longitudinal neuroimaging of ~9,500 children in the US, with multimodal data and 2.4mm/800ms fMRI scans.
          </li>
          <li>
            <b>Human Connectome Project – Young Adult (HCP-YA), Aging (HCP-A), Development (HCP-D):</b>
            Three high-resolution (2mm) public datasets for mapping brain structure and function across the lifespan (children, young adults, elderly).
          </li>
          <li>
            <b>Human Connectome Project – Early Psychosis (HCP-EP):</b>
            fMRI/clinical data for early psychosis research (252 subjects), 2mm, TR=800ms.
          </li>
          <li>
            <b>ADHD-200 Sample (ADHD200):</b>
            Multi-site data of 973 children/adolescents, 3×3×4mm, TR=2000ms, focused on ADHD diagnosis.
          </li>
          <li>
            <b>Autism Brain Imaging Data Exchange (ABIDE):</b>
            Aggregated from 17 sites, 1,112 subjects (948 males, 164 females) for ASD studies, 3mm, TR=2000ms.
          </li>
          <li>
            <b>UCLA Consortium for Neuropsychiatric Phenomics (UCLA):</b>
            272 subjects (multi-diagnostic), 3×3×4mm, TR=2000ms.
          </li>
          <li>
            <b>Center for Biomedical Research Excellence (COBRE):</b>
            173 subjects (schizophrenia and controls), 3.75×3.75×4.55mm, TR=2000ms.
          </li>
          <li>
            <b>Motor Neuron Disease fMRI Dataset (MND):</b>
            59 participants (ALS and controls), 2.4mm, TR=2000ms, collected in Australia.
          </li>
          <li>
            <b>Transdiagnostic Connectome Project (TCP):</b>
            245 subjects with multiple psychiatric diagnoses (2mm, TR=800ms), harmonized imaging.
          </li>
        </ul>

        <div class="container" style="margin-top:2em; margin-bottom:2em;">
          <div class="columns is-vcentered is-desktop">
            <div class="column has-text-centered">
              <figure>
                <img src="static/images/data_sun.png" alt="Dataset distribution sunburst plot" style="max-width:100%; height:380px; object-fit:contain;"/>
                <figcaption style="margin-top:0.5em; font-size:1em; color:#666;">Dataset and sex distribution overview.</figcaption>
              </figure>
            </div>
            <div class="column has-text-centered">
              <figure>
                <img src="static/images/sankey.png" alt="Sankey diagram for NeuroSTORM dataset composition" style="max-width:100%; height:380px; object-fit:contain;"/>
                <figcaption style="margin-top:0.5em; font-size:1em; color:#666;">Sample composition in NeuroSTORM datasets.</figcaption>
              </figure>
            </div>
          </div>
        </div>

      </div>
    </div>
  </div>
</section>
<!-- End supported Dataset -->


<!-- Supported downstream task -->
<section class="hero is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">3. Supported Tasks</h2>
      <div class="content">

        <h3>1. Age and Gender Prediction</h3>
        <p>
          This task evaluates the ability to predict demographic variables (age and biological sex) from resting-state fMRI (rsfMRI) sequences. It is a fundamental benchmark for assessing generalizable neural representations.
          <br>
          <b>How to use in NeuroSTORM:</b>
          <ul>
            <li>
              <b>Sex classification (reported):</b><br>
              <code>--downstream_task_id 1 --downstream_task_type classification --task_name sex</code>
            </li>
            <li>
              <b>Age prediction (regression):</b><br>
              <code>--downstream_task_id 1 --downstream_task_type regression --task_name age</code>
            </li>
          </ul>
        </p>

        <h3>2. Phenotype Prediction</h3>
        <p>
          This task focuses on predicting various cognitive, behavioral, or clinical phenotype scores from fMRI data. Each phenotype (e.g., MMSE Score, Social Task Score, PANSS, DASS, etc.) can be selected as a regression target.
          <br>
          <b>How to use in NeuroSTORM:</b>
          <ul>
            <li>
              <b>Phenotype regression:</b><br>
              <code>--downstream_task_id 2 --downstream_task_type regression --task_name your_score_name</code>
              <br>
              Replace <code>your_score_name</code> with the phenotype to predict (e.g., <code>MMSE</code>, <code>PANSS_Positive</code>).
            </li>
          </ul>
        </p>

        <h3>3. Disease Diagnosis</h3>
        <p>
          This task consists of classifying subjects into diagnostic categories (e.g., healthy control vs. disorder) based on their fMRI data. It is applicable to datasets such as HCP-EP, ABIDE, ADHD200, COBRE, UCLA, and MND.
          <br>
          <b>How to use in NeuroSTORM:</b>
          <ul>
            <li>
              <b>Disease classification:</b><br>
              <code>--downstream_task_id 3 --downstream_task_type classification --task_name diagnosis</code>
            </li>
          </ul>
        </p>

        <h3>4. fMRI Retrieval</h3>
        <p>
          This task explores the alignment between fMRI patterns and external semantic data (e.g. images, captions) for brain decoding and retrieval. <br>
          <b>Support for this task in NeuroSTORM will be released soon.</b>
        </p>

        <h3>5. Task-based fMRI State Classification</h3>
        <p>
          This task evaluates the model's ability to classify cognitive state or task condition from task-based fMRI (tfMRI) sequences. For example, differentiating between emotion, language, or gambling task states in HCP-YA.
          <br>
          <b>How to use in NeuroSTORM:</b>
          <ul>
            <li>
              <b>State classification:</b><br>
              <code>--downstream_task_id 5 --downstream_task_type classification --task_name state_classification</code>
            </li>
          </ul>
        </p>

      </div>
    </div>
  </div>
</section>
<!-- End supported downstream task-->


<!--BibTex citation -->
  <!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section> -->
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            Maintained by the <a href="https://www.ee.cuhk.edu.hk/~yxyuan/" target="_blank">AIM group</a> at the Chinese University of Hong Kong.
            <br> This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
